{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ccc95c",
   "metadata": {},
   "source": [
    "# Text Classification Using spaCy\n",
    "\n",
    "The goal of this exercise is to use *review data* `to predict` if an Amazon Alexa product review is **positive** or **negative**.\n",
    "\n",
    "This dataset consists of a nearly 3000 Amazon customer reviews (input text), star ratings, date of review, variant and feedback of various Amazon Alexa products like Alexa Echo, Echo dots, Alexa Firesticks etc. for learning how to train machine for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9e4e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517ab1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (3150, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Walnut Finish</td>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating       date         variation  \\\n",
       "0       5  31-Jul-18  Charcoal Fabric    \n",
       "1       5  31-Jul-18  Charcoal Fabric    \n",
       "2       4  31-Jul-18    Walnut Finish    \n",
       "3       5  31-Jul-18  Charcoal Fabric    \n",
       "4       5  31-Jul-18  Charcoal Fabric    \n",
       "\n",
       "                                    verified_reviews  feedback  \n",
       "0                                      Love my Echo!         1  \n",
       "1                                          Loved it!         1  \n",
       "2  Sometimes while playing a game, you can answer...         1  \n",
       "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
       "4                                              Music         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon = pd.read_csv(\"datas/amazon_alexa.tsv\",sep='\\t')\n",
    "\n",
    "print(f\"Shape of data: {df_amazon.shape}\")\n",
    "df_amazon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8424a33",
   "metadata": {},
   "source": [
    "# Understanding the Data\n",
    "\n",
    " - The data has five columns: rating, date, variation, verified_reviews, feedback.\n",
    " - *`rating`* denotes the rating each user gave the Alexa (out of 5).\n",
    " - *`date`* indicates the date of the review\n",
    " - *`variation`* describes which model the user reviewed.\n",
    " - *`verified_reviews`* contains the text of each review\n",
    " - *`feedback`* contains a sentiment label, with 1 denoting positive sentiment (the user liked it) and 0 denoting negative sentiment (the user didnâ€™t)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9d80f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3150 entries, 0 to 3149\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   rating            3150 non-null   int64 \n",
      " 1   date              3150 non-null   object\n",
      " 2   variation         3150 non-null   object\n",
      " 3   verified_reviews  3150 non-null   object\n",
      " 4   feedback          3150 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 123.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_amazon.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449a875d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2893\n",
       "0     257\n",
       "Name: feedback, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon.feedback.value_counts() # few reviews with negative feedback, therefore it may create problem during classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558b322",
   "metadata": {},
   "source": [
    "## Tokenizing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c89dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "806c30d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "punctuations = string.punctuation # creating list of punctuationmarks\n",
    "print(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab4d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03ee992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function will accept a sentence as input and processes it into tokens, performing lemmatization,\n",
    "    lowercasing, removing stopwords and punctuations.\n",
    "    \"\"\"\n",
    "    tokens = nlp(sentence) # creating the token object\n",
    "    \n",
    "    # checking the lowercase for pronouns\n",
    "    tokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens ]\n",
    "    \n",
    "    # removing stopwords and punctuations\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in punctuations]\n",
    "    \n",
    "    # returning preprocessed list of tokens\n",
    "    return tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeda961",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247f3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer using spaCy\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        \"\"\"\n",
    "        Override the transform method to clean text\n",
    "        \"\"\"\n",
    "        return [clean_text(text) for text in X]\n",
    "    \n",
    "    def fit(self, X, y= None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep= True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Removing spaces and converting the text into lowercase\n",
    "    \"\"\"\n",
    "    return text.strip().lower() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad8f839",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Vectorization\n",
    "\n",
    " The labels (feedback 0 and 1 in this case) are in numeric format. Using `Bag of Words(BoW)` to convert text into numeric format.\n",
    "**BoW** converts text into the matrix of occurrence of words within a given document. It focuses on whether given word occurred or not in given document and generate the matrix called as BoW matrix/Document Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "451e3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sklearn's CountVectorizer to generate BoW matrix\n",
    "# using unigram, in order to lower and upper bound of ngram range to be (1,1)\n",
    "bow_vector = CountVectorizer(tokenizer= spacy_tokenizer,ngram_range=(1,1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71598d79",
   "metadata": {},
   "source": [
    "### TF-IDF(Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "This is helpful to normalize the `Bag of Words(BoW)` by looking at each word's frequency in comparison to document frequency. It's a way of representing how important a particular term is, in the context of given document based on how many times that term appears and in how many documents it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37543fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127e889c",
   "metadata": {},
   "source": [
    "### Create Train and Test Datasets\n",
    "\n",
    "Train dataset will be used to *train the model* and test dataset to *test the model* performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b8bac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dimension: (2205,)\n",
      "y_train dimension: (2205,)\n",
      "X_test dimension: (945,)\n",
      "y_test dimension: (945,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_amazon['verified_reviews'] # the feature to analyze\n",
    "ylabels = df_amazon['feedback'] # the labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3,random_state=1)\n",
    "\n",
    "print(f'X_train dimension: {X_train.shape}')\n",
    "print(f'y_train dimension: {y_train.shape}')\n",
    "print(f'X_test dimension: {X_test.shape}')\n",
    "print(f'y_test dimension: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c52c87",
   "metadata": {},
   "source": [
    "### Creating a Pipeline and Generating the Model\n",
    "\n",
    "Using `LogisticRegression` classifier for review classification. \n",
    "\n",
    "The pipeline contains three components a **cleaner**, a **vectorizer** and a **classifier**.\n",
    " - `Cleaner:` Cleaner uses our 'predictors' class object to clean and preprocess the text.\n",
    " - `Vectorizer:` Vectorizer uses 'CountVectorizer' object to create the bag of words matrix for our text.\n",
    " - `Classifier:` It performs the logistic regression to classify the sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1943e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cleaner', <__main__.predictors object at 0x00000125A8C78340>),\n",
       "                ('vectorizer',\n",
       "                 CountVectorizer(tokenizer=<function spacy_tokenizer at 0x00000125A65B2A60>)),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Creating pipeline using BoW\n",
    "model = Pipeline([(\"cleaner\",predictors()),\n",
    "                 (\"vectorizer\",bow_vector),\n",
    "                 (\"classifier\",classifier)])\n",
    "\n",
    "# Model generation\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b352a5",
   "metadata": {},
   "source": [
    "### Model Score\n",
    "\n",
    "The model is trained using training data, now test data will be used for `model evaluation`.\n",
    "\n",
    "The metrics that will be used to evaluate the model:\n",
    " - `Accuracy` refers to the percentage of the total predictions the model makes that are completely correct.\n",
    " - `Precision` describes the ratio of true positives to true positives plus false positives in the predictions.\n",
    " - `Recall` describes the ratio of true positives to true positives plus false negatives in the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48256d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9375661375661376\n",
      "Logistic Regression Precision: 0.9501661129568106\n",
      "Logistic Regression Recall: 0.9839449541284404\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# predicting with the test dataset\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# model accuracy score\n",
    "print(f'Logistic Regression Accuracy: {metrics.accuracy_score(y_test, predicted)}')\n",
    "print(f'Logistic Regression Precision: {metrics.precision_score(y_test, predicted)}')\n",
    "print(f'Logistic Regression Recall: {metrics.recall_score(y_test, predicted)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79121a80",
   "metadata": {},
   "source": [
    "Overall, the model correctly identified a commentâ€™s sentiment **93.96%** of the time. When it predicted a review was positive, that review was actually positive **94.82%** of the time. When handed a positive review, the model identified it as positive **98.85%** of the time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
