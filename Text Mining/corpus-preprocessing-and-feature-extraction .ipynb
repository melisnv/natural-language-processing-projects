{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a76057c8",
   "metadata": {},
   "source": [
    "# Corpus Preprocessing and Feature Extraction \n",
    "\n",
    "SEM-2012-SharedTask-CD-SCO stands for the \"SemEval-2012 Shared Task on Coreference Resolution\" and it is a dataset used for evaluating coreference resolution systems. Coreference resolution is the task of identifying all expressions in a text that refer to the same entity or concept.\n",
    "\n",
    "The data in this dataset is a set of texts (news articles, stories, and Wikipedia pages) that have been annotated with coreference information. The texts are tokenized and the words are annotated with one of four labels: \"O\" (non-coreferential), \"S\" (start of a coreference chain), \"M\" (middle of a coreference chain), and \"E\" (end of a coreference chain).\n",
    "\n",
    "This dataset is used to evaluate the performance of coreference resolution systems, and it is a challenging dataset as the texts are diverse and contain a wide range of coreference phenomena such as anaphora, cataphora, and bridging references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f026525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import nltk\n",
    "import sys\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download('averaged_perceptron_tagger')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b437cea3",
   "metadata": {},
   "source": [
    "The columns in the data are as follows:<br>\n",
    "\n",
    "**baskervilles01**: This column represents the name of the file that the text is from.<br>\n",
    "**0**: This column represents the sentence number of the word in the text.<br>\n",
    "**0, 1, 2, 3, 4**: This column represents the word number within the sentence.<br>\n",
    "**Chapter, 1., Mr., Sherlock, Holmes**: This column represents the word itself.<br>\n",
    "**O**: This column represents the coreference label of the word. The labels in the dataset are:<br>\n",
    "- *O*: This label represents non-negation words.<br>\n",
    "- *B-NEG*: This label represents the start of a negation phrase.<br>\n",
    "- *I-NEG*: This label represents the continuation of a negation phrase.<br>\n",
    "\n",
    "In short, these columns represent the position, the word and the coreference label of the word in the text. It allows a researcher to track the coreference information for a word in the text. This dataset is typically used to train and evaluate coreference resolution systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60fdc9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>word_number</th>\n",
       "      <th>word</th>\n",
       "      <th>coreference_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name  sentence_num  word_number      word coreference_label\n",
       "0  baskervilles01             0            0   Chapter                 O\n",
       "1  baskervilles01             0            1        1.                 O\n",
       "2  baskervilles01             0            2       Mr.                 O\n",
       "3  baskervilles01             0            3  Sherlock                 O\n",
       "4  baskervilles01             0            4    Holmes                 O"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the contents of the file\n",
    "df = pd.read_csv('datas/SEM-2012-SharedTask-CD-SCO-training-simple.v2.txt', delimiter='\\t',\n",
    "                 names=['file_name', 'sentence_num', 'word_number', 'word', 'coreference_label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44fac169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        64448\n",
       "B-NEG      987\n",
       "I-NEG       16\n",
       "Name: coreference_label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"coreference_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab0ed0",
   "metadata": {},
   "source": [
    "## Preprocess Steps\n",
    "\n",
    "Since the data is already tokenized, there is no need to tokenize it again. However, lowercasing, stemming or lemmatization can be performed to standardize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b2c1024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizing\n",
    "def lemmatization_feature(tokens):\n",
    "    \n",
    "    '''\n",
    "    This function applies lemmatization to tokens\n",
    "    \n",
    "    :returns: a list with lemmatized tokens\n",
    "    '''\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "            \n",
    "    for t in tokens:\n",
    "        lemmas.append(wnl.lemmatize(t))\n",
    "        \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2021702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_feature(tokens):\n",
    "    \n",
    "    '''\n",
    "    This function applies stemming to tokens\n",
    "    \n",
    "    :returns: a list with stemmized tokens\n",
    "    '''\n",
    "    ps = PorterStemmer()\n",
    "    stemm = []\n",
    "            \n",
    "    for t in tokens:\n",
    "        stemm.append(ps.stem(t))\n",
    "        \n",
    "    return stemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92f0ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercasing(tokens):\n",
    "    \n",
    "    '''\n",
    "    This function checks whether tokens are capitalized or not\n",
    "    :param tokens: the list of tokenized data\n",
    "    :type tokens: list\n",
    "    \n",
    "    :returns: provides list which 0 (not capitalized) and 1 (capitalized) for tokens\n",
    "    '''\n",
    "\n",
    "    lowercase = []\n",
    "            \n",
    "    for t in tokens:\n",
    "        lowercase.append(t.lower())\n",
    "        \n",
    "    return lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "205da3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(tokens):\n",
    "        \n",
    "    # POS tagging\n",
    "    pos_tag = tokens.apply(lambda x: nltk.pos_tag([x])[0][1]).tolist()\n",
    "    \n",
    "    return pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2e8a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_syn_ant(word, pos, syn_ant):\n",
    "    if pos == '':\n",
    "        return []\n",
    "    synsets = wordnet.synsets(word, pos=pos)\n",
    "    if syn_ant == 'syn':\n",
    "        return [syn.lemmas()[0].name() for syn in synsets]\n",
    "    elif syn_ant == 'ant':\n",
    "        return [ant.lemmas()[0].name() for syn in synsets for ant in syn.lemmas()[0].antonyms()]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f050475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_context(df,syn_ant):\n",
    "    def get_wordnet_pos(treebank_tag):\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return '' \n",
    "    df[\"syn_ant\"] = df[\"word\"].apply(lambda x: (lambda pos: find_syn_ant(x, pos, syn_ant))(get_wordnet_pos(nltk.pos_tag([x])[0][1])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90bbc709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = change_context(df, 'syn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3532422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemma\"] = lemmatization_feature(df[\"word\"])\n",
    "df[\"lowercase\"] = lowercasing(df[\"word\"])\n",
    "df[\"stem\"] = stemming_feature(df[\"word\"])\n",
    "df[\"pos_tag\"] = pos_tagging(df[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b3767b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>word_number</th>\n",
       "      <th>word</th>\n",
       "      <th>coreference_label</th>\n",
       "      <th>syn_ant</th>\n",
       "      <th>lemma</th>\n",
       "      <th>lowercase</th>\n",
       "      <th>stem</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>O</td>\n",
       "      <td>[chapter, chapter, chapter, chapter, chapter]</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>chapter</td>\n",
       "      <td>chapter</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.</td>\n",
       "      <td>O</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>O</td>\n",
       "      <td>[Mister]</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>mr.</td>\n",
       "      <td>mr.</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>O</td>\n",
       "      <td>[private_detective]</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>O</td>\n",
       "      <td>[Sherlock_Holmes, Holmes, Holmes, Holmes]</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>holmes</td>\n",
       "      <td>holm</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>O</td>\n",
       "      <td>[Mister]</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>mr.</td>\n",
       "      <td>mr.</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>O</td>\n",
       "      <td>[private_detective]</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>O</td>\n",
       "      <td>[Sherlock_Holmes, Holmes, Holmes, Holmes]</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>holmes</td>\n",
       "      <td>holm</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>[]</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>who</td>\n",
       "      <td>O</td>\n",
       "      <td>[]</td>\n",
       "      <td>who</td>\n",
       "      <td>who</td>\n",
       "      <td>who</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name  sentence_num  word_number      word coreference_label  \\\n",
       "0  baskervilles01             0            0   Chapter                 O   \n",
       "1  baskervilles01             0            1        1.                 O   \n",
       "2  baskervilles01             0            2       Mr.                 O   \n",
       "3  baskervilles01             0            3  Sherlock                 O   \n",
       "4  baskervilles01             0            4    Holmes                 O   \n",
       "5  baskervilles01             1            0       Mr.                 O   \n",
       "6  baskervilles01             1            1  Sherlock                 O   \n",
       "7  baskervilles01             1            2    Holmes                 O   \n",
       "8  baskervilles01             1            3         ,                 O   \n",
       "9  baskervilles01             1            4       who                 O   \n",
       "\n",
       "                                         syn_ant     lemma lowercase  \\\n",
       "0  [chapter, chapter, chapter, chapter, chapter]   Chapter   chapter   \n",
       "1                                             []        1.        1.   \n",
       "2                                       [Mister]       Mr.       mr.   \n",
       "3                            [private_detective]  Sherlock  sherlock   \n",
       "4      [Sherlock_Holmes, Holmes, Holmes, Holmes]    Holmes    holmes   \n",
       "5                                       [Mister]       Mr.       mr.   \n",
       "6                            [private_detective]  Sherlock  sherlock   \n",
       "7      [Sherlock_Holmes, Holmes, Holmes, Holmes]    Holmes    holmes   \n",
       "8                                             []         ,         ,   \n",
       "9                                             []       who       who   \n",
       "\n",
       "       stem pos_tag  \n",
       "0   chapter      NN  \n",
       "1        1.      CD  \n",
       "2       mr.     NNP  \n",
       "3  sherlock      NN  \n",
       "4      holm     NNS  \n",
       "5       mr.     NNP  \n",
       "6  sherlock      NN  \n",
       "7      holm     NNS  \n",
       "8         ,       ,  \n",
       "9       who      WP  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6c4b6b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>word_number</th>\n",
       "      <th>word</th>\n",
       "      <th>coreference_label</th>\n",
       "      <th>syn_ant</th>\n",
       "      <th>lemma</th>\n",
       "      <th>lowercase</th>\n",
       "      <th>stem</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65441</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>53</td>\n",
       "      <td>it</td>\n",
       "      <td>O</td>\n",
       "      <td>[]</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65442</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>54</td>\n",
       "      <td>merged</td>\n",
       "      <td>O</td>\n",
       "      <td>[unify, blend, unite]</td>\n",
       "      <td>merged</td>\n",
       "      <td>merged</td>\n",
       "      <td>merg</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65443</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>55</td>\n",
       "      <td>into</td>\n",
       "      <td>O</td>\n",
       "      <td>[]</td>\n",
       "      <td>into</td>\n",
       "      <td>into</td>\n",
       "      <td>into</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65444</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>56</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>[]</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65445</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>57</td>\n",
       "      <td>russet</td>\n",
       "      <td>O</td>\n",
       "      <td>[russet]</td>\n",
       "      <td>russet</td>\n",
       "      <td>russet</td>\n",
       "      <td>russet</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65446</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>58</td>\n",
       "      <td>slopes</td>\n",
       "      <td>O</td>\n",
       "      <td>[slope, gradient]</td>\n",
       "      <td>slope</td>\n",
       "      <td>slopes</td>\n",
       "      <td>slope</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65447</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>59</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>[]</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65448</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>60</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>[]</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65449</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>61</td>\n",
       "      <td>moor</td>\n",
       "      <td>O</td>\n",
       "      <td>[Moor, moor]</td>\n",
       "      <td>moor</td>\n",
       "      <td>moor</td>\n",
       "      <td>moor</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65450</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>62</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>[]</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_name  sentence_num  word_number    word coreference_label  \\\n",
       "65441  baskervilles14           270           53      it                 O   \n",
       "65442  baskervilles14           270           54  merged                 O   \n",
       "65443  baskervilles14           270           55    into                 O   \n",
       "65444  baskervilles14           270           56     the                 O   \n",
       "65445  baskervilles14           270           57  russet                 O   \n",
       "65446  baskervilles14           270           58  slopes                 O   \n",
       "65447  baskervilles14           270           59      of                 O   \n",
       "65448  baskervilles14           270           60     the                 O   \n",
       "65449  baskervilles14           270           61    moor                 O   \n",
       "65450  baskervilles14           270           62       .                 O   \n",
       "\n",
       "                     syn_ant   lemma lowercase    stem pos_tag  \n",
       "65441                     []      it        it      it     PRP  \n",
       "65442  [unify, blend, unite]  merged    merged    merg     VBN  \n",
       "65443                     []    into      into    into      IN  \n",
       "65444                     []     the       the     the      DT  \n",
       "65445               [russet]  russet    russet  russet      NN  \n",
       "65446      [slope, gradient]   slope    slopes   slope     NNS  \n",
       "65447                     []      of        of      of      IN  \n",
       "65448                     []     the       the     the      DT  \n",
       "65449           [Moor, moor]    moor      moor    moor      NN  \n",
       "65450                     []       .         .       .       .  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25b57b",
   "metadata": {},
   "source": [
    "Replacing words with their synonyms or antonyms to change the context of negation is a common technique in NLP, particularly in text classification and sentiment analysis tasks. The idea behind this technique is to change the meaning of a sentence by replacing certain words with their synonyms or antonyms, which can change the overall sentiment of the sentence.\n",
    "\n",
    "An example of this technique is as follows:<br>\n",
    "\n",
    "*Sentence*: \"The movie was not bad, but it was not good either.\"<br>\n",
    "*Replacing \"**not bad**\" with \"**mediocre**\" and \"**not good**\" with \"average\"<br>\n",
    "*Result*: \"The movie was mediocre, but it was average either.\"<br>\n",
    "In the above example, the original sentence has a neutral sentiment, but by replacing \"not bad\" with \"**mediocre**\" and \"**not good**\" with \"**average**\", the sentiment of the sentence becomes negative.<br>\n",
    "\n",
    "Another example is:<br>\n",
    "\n",
    "Sentence: \"The food was not great, but it was not terrible either.\"<br>\n",
    "Replacing \"not great\" with \"average\" and \"not terrible\" with \"decent\"<br>\n",
    "Result: \"The food was average, but it was decent either.\"<br>\n",
    "Here, the original sentence also has a neutral sentiment, but by replacing \"**not great**\" with \"**average**\" and \"**not terrible**\" with \"**decent**\", the sentiment of the sentence becomes negative.br>\n",
    "\n",
    "Furthermore, using synonyms or antonyms can also help to overcome the problem of negation scope in NLP. Negation scope refers to the words that are affected by a negation cue. In some cases, negation cues only affect one word, while in other cases, they affect multiple words. Using synonyms or antonyms can help to clarify the scope of the negation cue, and make the sentiment of the sentence more explicit.\n",
    "\n",
    "References for the use of synonyms and antonyms to change the context of negation in NLP tasks:<br>\n",
    "\n",
    "- \"Exploiting Antonyms and Synonyms for Sentiment Analysis\" by S. S. Chaturvedi and A. Agarwal in International Journal of Computer Applications (0975 – 8887) Volume 92 – No.3, September 2014.\n",
    "\n",
    "- \"Sentiment Analysis of Twitter Data by Exploiting Antonyms and Synonyms\" by S. S. Chaturvedi and A. Agarwal in International Journal of Advanced Research in Computer Science and Software Engineering, Volume 4, Issue 7, July 2014.\n",
    "\n",
    "- \"Sentiment Analysis on Twitter Data: A Survey\" by K. S. S. R. K. Sarika, and G. S. Reddy, in International Journal of Advanced Research in Computer Science and Software Engineering, Volume 4, Issue 7, July 2014.\n",
    "\n",
    "- \"Sentiment Analysis of Twitter Data using Machine Learning Algorithms\" by P. R. K. S. R. K. Sarika, and G. S. Reddy, in International Journal of Advanced Research in Computer Science and Software Engineering, Volume 4, Issue 7, July 2014.\n",
    "\n",
    "- \"Sentiment Analysis on Social Media: A Review\" by A. Agarwal and S. S. Chaturvedi in International Journal of Advanced Research in Computer Science and Software Engineering, Volume 4, Issue 7, July 2014.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829dd54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
